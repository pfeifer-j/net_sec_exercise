{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Network Firewalls: Nftables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 1: What is netfilter, and what are nftables?\n",
    "\n",
    "Netfilter is a framework provided by the Linux kernel that allows various networking-related operations to be implemented in the form of customized handlers. It provides a set of hooks within the Linux kernel for intercepting and manipulating network packets.\n",
    "\n",
    "nf_tables is a subsystem of the Linux kernel responsible for packet filtering, NAT and packet mangling. It replaces the existing systems such as iptables and provides a single, unified and efficient framework for handling IPv4, IPv6, ARP and other packet types.\n",
    "\n",
    "## Task 2: What is the role of a table, chain, hook in nftables? What is the relationship between hook and priority in nftables?\n",
    "\n",
    "In nftables, a table is a container for chains. A chain is a sequence of rules which are evaluated in order for each packet. A hook determines at which point in the packet processing pipeline a chain (and its rules) are evaluated.\n",
    "\n",
    "The priority determines the order of evaluation when multiple hooks are registered at the same point in the packet processing pipeline. Lower priority values are processed first.\n",
    "\n",
    "## Task 3: Forward a TCP and UDP port using nftables. external Address: 1234 <- > 127.0.0.1:4321.\n",
    "\n",
    "```python\n",
    "# Add the following rules to your nftables configuration\n",
    "nft add rule ip filter forward tcp dport 1234 counter redirect to 4321\n",
    "nft add rule ip filter forward udp dport 1234 counter redirect to 4321\n",
    "```\n",
    "\n",
    "## Task 4: Echo packets using nftables.\n",
    "\n",
    "```python\n",
    "# Add the following rules to your nftables configuration\n",
    "nft add rule ip filter input tcp dport 9000 counter redirect to 1234\n",
    "nft add rule ip filter output udp dport 9000 counter drop\n",
    "```\n",
    "\n",
    "## Task 5:\n",
    "*Drop outgoing UDP packets via the default interface that contain the bytes 0xca 0xfe at position 100 (position in bytes, counted from the start of the UDP header). Which netfilter hook and priority do you need to use for that and why?*\n",
    "\n",
    "```python\n",
    "# Add the following rule to your nftables configuration\n",
    "nft add rule ip filter output udp payload 100 2 0xcafe counter drop\n",
    "```\n",
    "\n",
    "## Task 6:\n",
    "*Drop incoming TCP packets via the default interface that contains the bytes 0xbe 0xef at position 10000 (position in bytes, counted from the start of the TCP header). Which netfilter hook and priority do you need to use and why?*\n",
    "\n",
    "```python\n",
    "# Add the following rule to your nftables configuration\n",
    "nft add rule ip filter input tcp payload 10000 2 0xbeef counter drop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Network Monitoring using Libpcap and Tcpdump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Simple Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Count the number of packets in the network trace. For that, create the fundamental structure of your application to retrieve packets through libpcap and implement a counter to verify the general working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of packets: 1000000\n"
     ]
    }
   ],
   "source": [
    "import pcap\n",
    "\n",
    "# task 2.1\n",
    "def count_packets(pcap_file):\n",
    "    packet_count = 0\n",
    "    for timestamp, packet in pcap.pcap(pcap_file):\n",
    "        packet_count += 1\n",
    "    print(f\"Total number of packets: {packet_count}\")\n",
    "    \n",
    "pcap_file_path = 'sample1m.pcap'\n",
    "count_packets(pcap_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Considering IPv4 only, count the number of packets, the number of IPs, and the amount of transmitted payload. Does the trace contain more network protocols? Identify all present network (layer 3) protocols and count the packets per protocol. Specifically for IPv4, parse the header to analyze the IP addresses and payload data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPv4 packets: 873244\n",
      "Unique IPs: 235352\n",
      "Total IPv4 payload: 699371757 bytes\n",
      "Packets per protocol: {17: 92168, 6: 571537, 1: 196534, 47: 12570, 50: 10, 41: 425}\n"
     ]
    }
   ],
   "source": [
    "import pcap\n",
    "import struct\n",
    "\n",
    "#task 2.2\n",
    "def count_packets(pcap_file):\n",
    "    ipv4_count = 0\n",
    "    unique_ips = set()\n",
    "    protocol_counts = {}\n",
    "    total_payload = 0\n",
    "    \n",
    "    for timestamp, packet in pcap.pcap(pcap_file):\n",
    "        #unpack ethernet header (6 bytes dest MAC, 6 bytes src MAC, 2 bytes protocol)\n",
    "        eth_header = struct.unpack('!6s6sH', packet[:14]) \n",
    "        eth_protocol = eth_header[2]\n",
    "        \n",
    "        # check for IPv4 packets (0x0800)\n",
    "        if eth_protocol == 0x0800:\n",
    "            ipv4_count += 1\n",
    "            ip_header = struct.unpack('!BBHHHBBH4s4s', packet[14:34])\n",
    "            protocol = ip_header[6]\n",
    "            src_ip = packet[26:30]\n",
    "            dst_ip = packet[30:34]\n",
    "            unique_ips.update([src_ip, dst_ip])\n",
    "            \n",
    "            # Calculate payload size\n",
    "            total_length = ip_header[2]\n",
    "            header_length = (ip_header[0] & 0xF) * 4\n",
    "            payload_size = total_length - header_length\n",
    "            total_payload += payload_size\n",
    "            \n",
    "            # Count packets per protocol\n",
    "            if protocol in protocol_counts:\n",
    "                protocol_counts[protocol] += 1\n",
    "            else:\n",
    "                protocol_counts[protocol] = 1\n",
    "    \n",
    "    print(f\"IPv4 packets: {ipv4_count}\")\n",
    "    print(f\"Unique IPs: {len(unique_ips)}\")\n",
    "    print(f\"Total IPv4 payload: {total_payload} bytes\")\n",
    "    print(\"Packets per protocol:\", protocol_counts)\n",
    "\n",
    "pcap_file_path = 'sample1m.pcap'\n",
    "count_packets(pcap_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Considering IPv4 only, \n",
    "how many bytes of payloads are transmitted over TCP and UDP? \n",
    "Does the trace contain more transport protocols? \n",
    "Are there packets with inconsistency regarding their payload length? \n",
    "Identify all present transport (layer4) protocols over IPv4 and parse TCP/UDP packets to analyze the payload bytes.\n",
    "Are there any indications that someone is deliberately sending unusual packets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCP Payload Bytes: 613657088\n",
      "UDP Payload Bytes: 80256331\n",
      "Other Protocols: {1: 2772733, 47: 2489746, 50: 1740, 41: 194119}\n",
      "Inconsistencies: 0\n"
     ]
    }
   ],
   "source": [
    "import pcap\n",
    "import struct\n",
    "\n",
    "tcp_payload_bytes = 0\n",
    "udp_payload_bytes = 0\n",
    "other_protocols = {}\n",
    "inconsistencies = 0\n",
    "unusual_packets = []\n",
    "\n",
    "def parse_packet(timestamp, packet):\n",
    "    global tcp_payload_bytes, udp_payload_bytes, inconsistencies\n",
    "    \n",
    "    # Ethernet header is 14 bytes long, IP header starts immediately after\n",
    "    eth_header = struct.unpack(\"!6s6s2s\", packet[:14])\n",
    "    eth_type = eth_header[2]\n",
    "    \n",
    "    # Check if it's an IP packet (0x0800)\n",
    "    if eth_type != b'\\x08\\x00':\n",
    "        print(\"Non-IP Packet type not supported\")\n",
    "        return\n",
    "    \n",
    "    # IP header extraction\n",
    "    ip_header = packet[14:34]  # IP header is after Ethernet header (14 bytes)\n",
    "    iph = struct.unpack('!BBHHHBBH4s4s', ip_header)\n",
    "    version_ihl = iph[0]\n",
    "    ihl = version_ihl & 0xF\n",
    "    iph_length = ihl * 4\n",
    "    protocol = iph[6]\n",
    "    total_length = iph[2]\n",
    "    \n",
    "    # Calculate payload size\n",
    "    payload_size = total_length - iph_length\n",
    "    \n",
    "    # Check protocol and update counters\n",
    "    if protocol == 6:  # TCP\n",
    "        tcp_payload_bytes += payload_size\n",
    "    elif protocol == 17:  # UDP\n",
    "        udp_payload_bytes += payload_size\n",
    "    else:\n",
    "        if protocol not in other_protocols:\n",
    "            other_protocols[protocol] = payload_size\n",
    "        else:\n",
    "            other_protocols[protocol] += payload_size\n",
    "    \n",
    "    # Example inconsistency check (simplified)\n",
    "    if payload_size < 0:\n",
    "        inconsistencies += 1\n",
    "    \n",
    "    # Example check for unusual packets (simplified)\n",
    "    if payload_size > 10000:\n",
    "        unusual_packets.append(packet)\n",
    "\n",
    "# Open pcap file\n",
    "pc = pcap.pcap(name='sample1m.pcap')\n",
    "pc.setfilter('ip')  # Filter for IP packets only\n",
    "\n",
    "# Parse each packet\n",
    "for timestamp, packet in pc:\n",
    "    parse_packet(timestamp, packet)\n",
    "\n",
    "# Output findings\n",
    "print(f\"TCP Payload Bytes: {tcp_payload_bytes}\")\n",
    "print(f\"UDP Payload Bytes: {udp_payload_bytes}\")\n",
    "print(f\"Other Protocols: {other_protocols}\")\n",
    "print(f\"Inconsistencies: {inconsistencies}\")\n",
    "if unusual_packets:\n",
    "    print(f\"Found {len(unusual_packets)} unusual packets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Count the number of flows and identify the most chatty conversations on the network and transport layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Network Flows: 280626\n",
      "Most Chatty Network Flow: ('23.26.144.53', '163.139.25.45') with 336173980 bytes\n",
      "Total Transport Flows: 99992\n",
      "Most Chatty Transport Flow: ('23.26.144.53', 80, '163.139.25.45', 18748, 6) with 195542719 bytes\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import struct\n",
    "import pcap\n",
    "\n",
    "network_flows = {}\n",
    "transport_flows = {}\n",
    "\n",
    "def parse_packet(timestamp, packet):\n",
    "    global network_flows, transport_flows\n",
    "    \n",
    "    # get ethernet header (6 bytes dest MAC, 6 bytes src MAC, 2 bytes protocol)\n",
    "    eth_header = struct.unpack(\"!6s6s2s\", packet[:14])\n",
    "    eth_type = eth_header[2]\n",
    "    \n",
    "    if eth_type != b'\\x08\\x00':\n",
    "        return  # Skip non-IP packets\n",
    "    \n",
    "    ip_header = packet[14:34]  # IP header is after Ethernet header (14 bytes)\n",
    "    iph = struct.unpack('!BBHHHBBH4s4s', ip_header) # IP header format\n",
    "    version_ihl = iph[0]\n",
    "    ihl = version_ihl & 0xF\n",
    "    iph_length = ihl * 4\n",
    "    protocol = iph[6]\n",
    "    total_length = iph[2]\n",
    "    src_ip = socket.inet_ntoa(iph[8])\n",
    "    dst_ip = socket.inet_ntoa(iph[9])\n",
    "    \n",
    "    # payload size = total length - header length\n",
    "    payload_size = total_length - iph_length\n",
    "    \n",
    "    network_flow = (src_ip, dst_ip)\n",
    "    # Update network flow with payload size\n",
    "    network_flows[network_flow] = network_flows.get(network_flow, 0) + payload_size\n",
    "    \n",
    "    if len(packet) < 14 + iph_length + 4:\n",
    "        return  # packet too short for TCP/UDP header\n",
    "    \n",
    "    # TCP or UDP\n",
    "    if protocol == 6 or protocol == 17: \n",
    "        src_port, dst_port = struct.unpack('!HH', packet[14+iph_length:14+iph_length+4])\n",
    "        transport_flow = (src_ip, src_port, dst_ip, dst_port, protocol)\n",
    "        transport_flows[transport_flow] = transport_flows.get(transport_flow, 0) + payload_size\n",
    "\n",
    "\n",
    "pc = pcap.pcap(name='sample1m.pcap')\n",
    "pc.setfilter('ip')  # Filter for IP packets only\n",
    "\n",
    "for timestamp, packet in pc:\n",
    "    parse_packet(timestamp, packet)\n",
    "\n",
    "# get maximum flows \n",
    "most_chatty_network_flow = max(network_flows, key=network_flows.get, default=\"No Flows\")\n",
    "most_chatty_transport_flow = max(transport_flows, key=transport_flows.get, default=\"No Flows\")\n",
    "\n",
    "# print results\n",
    "print(f\"Total Network Flows: {len(network_flows)}\")\n",
    "print(f\"Most Chatty Network Flow: {most_chatty_network_flow} with {network_flows.get(most_chatty_network_flow, 0)} bytes\")\n",
    "print(f\"Total Transport Flows: {len(transport_flows)}\")\n",
    "print(f\"Most Chatty Transport Flow: {most_chatty_transport_flow} with {transport_flows.get(most_chatty_transport_flow, 0)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Identify HTTP requests that submit login credentials via basic HTTP Auth. For\n",
    "that, use the network trace illauth.pcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Basic Auth Credentials (Base64): aGJkYWlyeWU0OmNoZWVzZWNha2U=\n",
      "Found Basic Auth Credentials (Base64): aGJkYWlyeWU0OmNoZWVzZWNha2U=\n"
     ]
    }
   ],
   "source": [
    "import pcap\n",
    "import socket\n",
    "import struct\n",
    "\n",
    "def parse_http_auth_credentials(pcap_file):\n",
    "    pc = pcap.pcap(pcap_file)\n",
    "    pc.setfilter('tcp port 80')  # Filter for HTTP traffic\n",
    "\n",
    "    for timestamp, packet in pc:\n",
    "        if len(packet) < 14 + 20 + 20:  # Ethernet + minimum IP header + minimum TCP header\n",
    "            continue\n",
    "\n",
    "        # Ethernet header is 14 bytes, IP header is 20 bytes minimum\n",
    "        ip_header = packet[14:34]\n",
    "        iph = struct.unpack('!BBHHHBBH4s4s', ip_header)\n",
    "        iph_length = (iph[0] & 0xF) * 4\n",
    "\n",
    "        # Needs to be long enough to contain the full IP header and a TCP header\n",
    "        if len(packet) < 14 + iph_length + 20:\n",
    "            continue\n",
    "\n",
    "        tcp_header = packet[14+iph_length:14+iph_length+20]\n",
    "        \n",
    "        if len(tcp_header) < 20:\n",
    "            continue\n",
    "\n",
    "        tcph = struct.unpack('!HHLLBBHHH', tcp_header)\n",
    "        tcp_length = (tcph[4] >> 4) * 4\n",
    "        payload_start = 14 + iph_length + tcp_length\n",
    "        payload = packet[payload_start:]\n",
    "\n",
    "        try:\n",
    "            payload = payload.decode('utf-8')\n",
    "            headers = payload.split('\\r\\n')\n",
    "            for header in headers:\n",
    "                # check for Authorization header\n",
    "                if header.startswith('Authorization: Basic '):\n",
    "                    credentials = header.split(' ')[2]\n",
    "                    print(f\"Found Basic Auth Credentials (Base64): {credentials}\")\n",
    "                    break\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "\n",
    "parse_http_auth_credentials('illauth.pcap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Attack Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario 1: Identifying IP addresses that did not finish the three-way TCP handshake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 IP addresses with incomplete handshakes:\n",
      "125.129.161.32: 7229 incomplete handshakes\n",
      "185.247.198.175: 2218 incomplete handshakes\n",
      "5.247.225.198: 2024 incomplete handshakes\n",
      "5.247.225.196: 2003 incomplete handshakes\n",
      "5.247.225.197: 1965 incomplete handshakes\n"
     ]
    }
   ],
   "source": [
    "import pcap\n",
    "import socket\n",
    "import struct\n",
    "\n",
    "# Initialize data structures\n",
    "tcp_handshakes = {}\n",
    "incomplete_handshakes = {}\n",
    "\n",
    "def update_handshake_state(packet, iph_length, src_ip, dst_ip):\n",
    "    # Extract TCP header and flags\n",
    "    tcp_header = packet[14+iph_length:14+iph_length+20]\n",
    "    src_port, dst_port, _, _, tcp_flags = struct.unpack('!HHLLH', tcp_header[:14])\n",
    "    syn_flag = (tcp_flags & 0x02) >> 1\n",
    "    ack_flag = tcp_flags & 0x01\n",
    "    \n",
    "    # flow is defined by 4-tuple (src_ip, dst_ip, src_port, dst_port)\n",
    "    flow_key = (src_ip, dst_ip, src_port, dst_port)\n",
    "    \n",
    "    # Update handshake state\n",
    "    if syn_flag and not ack_flag:\n",
    "        tcp_handshakes[flow_key] = 'SYN_SENT'\n",
    "    elif syn_flag and ack_flag:\n",
    "        tcp_handshakes[flow_key] = 'SYN_ACK_RECEIVED'\n",
    "    elif not syn_flag and ack_flag and tcp_handshakes.get(flow_key) == 'SYN_SENT':\n",
    "        tcp_handshakes[flow_key] = 'HANDSHAKE_COMPLETED'\n",
    "\n",
    "def parse_packet(packet):\n",
    "    # Parse IP header\n",
    "    eth_header = struct.unpack(\"!6s6s2s\", packet[:14])\n",
    "    eth_type = eth_header[2]\n",
    "    if eth_type != b'\\x08\\x00':  # Not an IP packet\n",
    "        return\n",
    "    \n",
    "    ip_header = packet[14:34]\n",
    "    iph = struct.unpack('!BBHHHBBH4s4s', ip_header)\n",
    "    ihl = (iph[0] & 0xF) * 4\n",
    "    protocol = iph[6]\n",
    "    src_ip = socket.inet_ntoa(iph[8])\n",
    "    dst_ip = socket.inet_ntoa(iph[9])\n",
    "\n",
    "    \n",
    "    if protocol == 6:  # TCP\n",
    "        update_handshake_state(packet, ihl, src_ip, dst_ip)\n",
    "\n",
    "pc = pcap.pcap('sample1m.pcap')\n",
    "\n",
    "for timestamp, packet in pc:\n",
    "    parse_packet(packet)\n",
    "\n",
    "for flow, state in tcp_handshakes.items():\n",
    "    if state == 'SYN_SENT':\n",
    "        src_ip = flow[0]\n",
    "        incomplete_handshakes[src_ip] = incomplete_handshakes.get(src_ip, 0) + 1\n",
    "\n",
    "# get top 5 IP addresses\n",
    "top_5_ips = sorted(incomplete_handshakes.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "# Print results\n",
    "print(\"Top 5 IP addresses with incomplete handshakes:\")\n",
    "for ip, count in top_5_ips:\n",
    "    print(f\"{ip}: {count} incomplete handshakes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario 2: Identifying IP addresses that receive an ICMP port un- reachable packet in response to initiating a UDP communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 IP addresses with ICMP port unreachable packets in response to UDP:\n",
      "163.139.103.125: 5\n",
      "79.150.193.228: 2\n",
      "13.144.197.61: 2\n"
     ]
    }
   ],
   "source": [
    "import pcap\n",
    "import socket\n",
    "import struct\n",
    "\n",
    "icmp_unreachable_counts = {}\n",
    "udp_flows = set() \n",
    "\n",
    "def parse_packet(packet):\n",
    "    eth_header = struct.unpack(\"!6s6s2s\", packet[:14])\n",
    "    eth_type = eth_header[2]\n",
    "    if eth_type != b'\\x08\\x00':  # Not an IP packet\n",
    "        return\n",
    "    \n",
    "    ip_header = packet[14:34]\n",
    "    iph = struct.unpack('!BBHHHBBH4s4s', ip_header)\n",
    "    ihl = (iph[0] & 0xF) * 4\n",
    "    protocol = iph[6]\n",
    "    src_ip = socket.inet_ntoa(iph[8])\n",
    "    dst_ip = socket.inet_ntoa(iph[9])\n",
    "    \n",
    "    if protocol == 17:  # UDP\n",
    "        if len(packet) >= 14 + ihl + 8:\n",
    "            udp_header = packet[14+ihl:14+ihl+8]\n",
    "            src_port, dst_port = struct.unpack('!HH', udp_header[:4])\n",
    "            # Add UDP flow to tracking\n",
    "            udp_flows.add((src_ip, dst_ip, src_port, dst_port))\n",
    "        else:\n",
    "            pass # skip packets that are too short\n",
    "        \n",
    "    elif protocol == 1:  # ICMP\n",
    "        icmp_header = packet[14+ihl:14+ihl+4]\n",
    "        icmp_type, code = struct.unpack('!BB', icmp_header[:2])\n",
    "        if icmp_type == 3 and code == 3:  # ICMP port unreachable\n",
    "            original_ip_header = packet[14+ihl+8:14+ihl+8+20]\n",
    "            original_iph = struct.unpack('!BBHHHBBH4s4s', original_ip_header)\n",
    "            original_src_ip = socket.inet_ntoa(original_iph[8])\n",
    "            original_dst_ip = socket.inet_ntoa(original_iph[9])\n",
    "            original_udp_header = packet[14+ihl+8+20:14+ihl+8+20+8]\n",
    "            original_src_port, original_dst_port = struct.unpack('!HH', original_udp_header[:4])\n",
    "            \n",
    "            # Check if this ICMP packet corresponds to a tracked UDP flow\n",
    "            if (original_dst_ip, original_src_ip, original_dst_port, original_src_port) in udp_flows:\n",
    "                # Increment count \n",
    "                icmp_unreachable_counts[dst_ip] = icmp_unreachable_counts.get(dst_ip, 0) + 1\n",
    "\n",
    "pc = pcap.pcap('sample1m.pcap')\n",
    "\n",
    "for timestamp, packet in pc:\n",
    "    parse_packet(packet)\n",
    "\n",
    "sorted_ips = sorted(icmp_unreachable_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "top_5_ips = sorted_ips[:5]\n",
    "\n",
    "# Print results\n",
    "print(\"Top 5 IP addresses with ICMP port unreachable packets in response to UDP:\")\n",
    "for ip, count in top_5_ips:\n",
    "    print(f\"{ip}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tcpdump "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To read the given pcap file and write the first 10000 packets to another capture file we used\n",
    "\n",
    "```\n",
    "# tcpdump -r sample1m.pcap -w sample.pcap -c 10000\n",
    "\n",
    "```\n",
    "2. Then, to verify the number of packets in the new capture, we executed\n",
    "\n",
    "```\n",
    "# tcpdump -r sample.pcap -n | wc -l\n",
    "```\n",
    "\n",
    "3. To list the top five talkers in the new sample we called\n",
    "\n",
    "```\n",
    "# tcpdump -nnr sample.pcap | awk -F\" \" '{print $3}' | sort | uniq -c | sort -nr | head -5\n",
    "```\n",
    "Which yields \n",
    "```\n",
    "2808 23.26.144.53.80\n",
    "1324 203.194.219.227\n",
    " 463 183.175.123.12.443\n",
    " 434 104.134.68.10.443\n",
    " 194 2001:fdc7:6c7:e2d0:e009:bf8e:ff79:a6d2.50695\n",
    "```\n",
    "\n",
    "4. To list packets with TCP Reset Flags we used\n",
    "\n",
    "```\n",
    "# tcpdump -nnr sample.pcap 'tcp[13] & 4 != 0'\n",
    "```\n",
    "Which outputs \n",
    "```\n",
    "06:00:00.393431 IP 133.7.179.211.1688 > 125.129.161.32.37910: Flags [R.], seq 0, ack 2361643466, win 0, length 0\n",
    "06:00:00.398695 IP 5.247.201.219.40447 > 203.194.205.99.8088: Flags [R], seq 3742792195, win 1200, length 0\n",
    "06:00:00.399092 IP 133.7.227.119.1505 > 5.50.89.204.50555: Flags [R.], seq 0, ack 3035865952, win 0, length 0\n",
    "06:00:00.404464 IP 176.183.7.18.48119 > 133.238.15.5.59723: Flags [R], seq 503064290, win 1200, length 0\n",
    "06:00:00.405412 IP 203.194.195.84.11211 > 196.59.215.189.59175: Flags [R.], seq 0, ack 3429023779, win 0, length 0\n",
    "06:00:00.417526 IP 133.7.209.189.1688 > 125.129.161.32.33669: Flags [R.], seq 0, ack 1161876995, win 0, length 0\n",
    "06:00:00.421212 IP 133.238.12.81.8545 > 206.189.117.123.35886: Flags [R.], seq 0, ack 1086435738, win 65535, length 0\n",
    "06:00:00.432755 IP 203.194.193.23.32089 > 91.154.198.49.80: Flags [R.], seq 1168525437, ack 3682231626, win 60, length 0\n",
    "06:00:00.432780 IP 203.194.193.23.32089 > 91.154.198.49.80: Flags [R.], seq 0, ack 911, win 60, length 0\n",
    "06:00:00.437393 IP 5.247.225.196.54273 > 202.74.62.220.22376: Flags [R], seq 3740515204, win 1200, length 0\n",
    "06:00:00.437478 IP 203.194.194.208.33880 > 194.19.145.252.52457: Flags [R.], seq 0, ack 33509389, win 0, length 0\n",
    "06:00:00.441181 IP 176.183.5.228.40408 > 203.194.193.254.58097: Flags [R], seq 559880004, win 1200, length 0\n",
    "06:00:00.442948 IP 133.238.14.63.1688 > 125.129.161.32.50644: Flags [R.], seq 0, ack 1755134450, win 65535, length 0\n",
    "06:00:00.443688 IP 133.7.138.32.464 > 5.50.89.205.50469: Flags [R.], seq 0, ack 2257123250, win 0, length 0\n",
    "06:00:00.443936 IP 49.150.51.188.59216 > 163.139.51.41.993: Flags [R], seq 271487112, win 0, length 0\n",
    "06:00:00.446376 IP 5.247.225.198.53972 > 203.194.206.213.19315: Flags [R], seq 1026780058, win 1200, length 0\n",
    "06:00:00.450353 IP 133.238.14.154.23 > 209.244.217.224.29187: Flags [R.], seq 0, ack 2240416411, win 18512, length 0\n",
    "06:00:00.459866 IP 5.247.201.219.40447 > 203.194.205.10.8088: Flags [R], seq 2019600399, win 1200, length 0\n",
    "06:00:00.467766 IP 5.247.201.219.40447 > 203.194.206.19.8088: Flags [R], seq 429684133, win 1200, length 0\n",
    "```\n",
    "\n",
    "5. To only capture HTTP data packets on port 80 and avoid capturing the TCP session setup packets\n",
    "```\n",
    "# tcpdump -nnr sample.pcap 'tcp port 80 and (tcp[13] & 7 == 0)'\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "reading from PCAP-NG file sample.pcap\n",
    "06:00:00.392892 IP 17.139.176.81.80 > 163.139.101.107.51153: Flags [.], seq 296862263:296863637, ack 2208581056, win 118, options [nop,nop,TS val 925115841 ecr 798460735], length 1374: HTTP\n",
    "06:00:00.392909 IP 17.139.176.81.80 > 163.139.101.107.51153: Flags [.], seq 1374:2748, ack 1, win 118, options [nop,nop,TS val 925115841 ecr 798460735], length 1374: HTTP\n",
    "06:00:00.393110 IP 17.139.176.81.80 > 163.139.101.107.51153: Flags [.W], seq 16488:17862, ack 1, win 118, options [nop,nop,TS val 925115841 ecr 798460736], length 1374: HTTP\n",
    "[...]\n",
    "06:00:00.468770 IP 23.26.144.53.80 > 163.139.25.45.18727: Flags [.], seq 4094689:4096149, ack 1, win 229, length 1460: HTTP\n",
    "06:00:00.468787 IP 23.26.144.53.80 > 163.139.25.45.18727: Flags [.], seq 4096149:4097609, ack 1, win 229, length 1460: HTTP\n",
    "```\n",
    "\n",
    "6. A simple approach to detect the presence of port scans using tcpdump, can be done by counting the number of SYN's and compare them to the number of SYN-ACK's. \n",
    "Count SYN:\n",
    "```\n",
    "# tcpdump -nnr sample.pcap 'tcp[13] & 2 != 0' | wc -l\n",
    "```\n",
    "Output: \n",
    "```\n",
    "666\n",
    "```\n",
    "\n",
    "Count SYN-ACK:\n",
    "```\n",
    "tcpdump -nnr sample.pcap 'tcp[13] = 18' | wc -l\n",
    "```\n",
    "Output:\n",
    "```\n",
    "61\n",
    "```\n",
    "This indicates a SYN scan is present in the sample."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
